{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "555dde42",
   "metadata": {},
   "source": [
    "## 🔶 1. Power BI Fundamentals\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ What is Power BI?\n",
    "\n",
    "**Power BI** is a powerful business analytics tool developed by Microsoft that enables users to visualize data, share insights, and make data-driven decisions. It transforms raw data into informative and interactive dashboards and reports.\n",
    "\n",
    "**Key Features:**\n",
    "\n",
    "* Data visualization with interactive dashboards\n",
    "* Integration with hundreds of data sources (Excel, SQL Server, Azure, web, etc.)\n",
    "* Real-time analytics and dashboard sharing\n",
    "* AI-powered insights (like Q\\&A visuals and anomaly detection)\n",
    "* Strong integration with Excel and Microsoft ecosystem\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Why is Power BI Important in the ETL Process?\n",
    "\n",
    "**ETL (Extract, Transform, Load)** is a crucial process in data preparation. Power BI includes built-in tools, primarily **Power Query**, to handle all three stages:\n",
    "\n",
    "| ETL Stage     | Role in Power BI                                                |\n",
    "| ------------- | --------------------------------------------------------------- |\n",
    "| **Extract**   | Pull data from various sources (databases, Excel, APIs, etc.)   |\n",
    "| **Transform** | Clean, shape, and structure data using Power Query Editor       |\n",
    "| **Load**      | Load the transformed data into the Power BI model for reporting |\n",
    "\n",
    "**Benefits of using ETL in Power BI:**\n",
    "\n",
    "* Ensures cleaner, more accurate data before analysis\n",
    "* Reduces manual data prep time\n",
    "* Handles both small and enterprise-level datasets\n",
    "* Enables data profiling to detect anomalies early\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Power BI Interface & Workflow Overview\n",
    "\n",
    "Power BI Desktop has several main components you work with:\n",
    "\n",
    "#### 💡 Power BI Desktop Views:\n",
    "\n",
    "1. **Report View**: Where visualizations and dashboards are created.\n",
    "2. **Data View**: See your data in tabular form after loading.\n",
    "3. **Model View**: View and manage relationships between tables.\n",
    "\n",
    "#### 💡 Power BI Workflow:\n",
    "\n",
    "1. **Connect** to a data source via “Get Data”\n",
    "2. **Transform** data using **Power Query Editor**\n",
    "3. **Load** data into Power BI model\n",
    "4. **Create Reports** using visuals like charts, maps, and KPIs\n",
    "5. **Publish** to Power BI Service for sharing and collaboration\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Summary\n",
    "\n",
    "| Topic                | Key Points                                                                       |\n",
    "| -------------------- | -------------------------------------------------------------------------------- |\n",
    "| What is Power BI?    | Microsoft tool for data analysis and visualization                               |\n",
    "| ETL in Power BI      | Helps extract, clean, and prepare data for analysis                              |\n",
    "| Interface & Workflow | Involves loading data, transforming it, building visuals, and publishing reports |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5290db30",
   "metadata": {},
   "source": [
    "## 🔶 2. Connecting to Data Sources\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Supported Data Sources in Power BI\n",
    "\n",
    "Power BI offers **extensive support** for a wide range of data sources—both cloud-based and on-premises. These include:\n",
    "\n",
    "#### 🔹 File-Based Sources\n",
    "\n",
    "* Excel\n",
    "* CSV\n",
    "* XML\n",
    "* JSON\n",
    "* PDF\n",
    "* Folder\n",
    "\n",
    "#### 🔹 Database Sources\n",
    "\n",
    "* SQL Server\n",
    "* MySQL\n",
    "* PostgreSQL\n",
    "* Oracle\n",
    "* IBM DB2\n",
    "* Microsoft Access\n",
    "* Azure SQL Database / Data Lake\n",
    "\n",
    "#### 🔹 Online Services & Cloud\n",
    "\n",
    "* SharePoint Online\n",
    "* OneDrive\n",
    "* Google Analytics\n",
    "* Salesforce\n",
    "* Dynamics 365\n",
    "* Azure Blob Storage\n",
    "* Web APIs (using REST)\n",
    "\n",
    "#### 🔹 Others\n",
    "\n",
    "* Blank Queries (to write M-code)\n",
    "* ODBC and OLE DB connections\n",
    "* Power Platform sources (e.g., Power BI datasets, Power Apps, Power Automate)\n",
    "\n",
    "> 📌 Tip: You can access these using the **“Get Data”** button on the Home ribbon in Power BI Desktop.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Local Datasets vs. Shared Datasets\n",
    "\n",
    "| Feature           | Local Dataset                    | Shared Dataset                                   |\n",
    "| ----------------- | -------------------------------- | ------------------------------------------------ |\n",
    "| **Scope**         | Used only within a single report | Can be reused across multiple reports            |\n",
    "| **Management**    | Changes are local and isolated   | Centralized updates impact all connected reports |\n",
    "| **Collaboration** | Not ideal for team-based work    | Enables consistency in data across teams         |\n",
    "| **Example**       | Imported Excel file              | Dataset published to Power BI Service            |\n",
    "\n",
    "> 🔸 Use **shared datasets** for standardized, scalable, and collaborative reporting.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Power BI Connectors\n",
    "\n",
    "Power BI provides **built-in connectors** that help you connect quickly to various sources.\n",
    "\n",
    "#### 💡 Types of Connectors:\n",
    "\n",
    "* **Certified Connectors**: Microsoft-supported and secure\n",
    "* **Third-party Connectors**: Created by the community or vendors\n",
    "* **Beta/Preview Connectors**: Experimental and may lack full support\n",
    "\n",
    "> 🟡 **Best Practice**: Avoid using Beta/Preview connectors in production environments.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ How to Connect to Excel, Databases, and Cloud Sources\n",
    "\n",
    "#### 🔷 Connecting to an Excel File\n",
    "\n",
    "1. Click **Get Data** → Select **Excel**\n",
    "2. Browse and load the workbook\n",
    "3. Choose sheets or tables\n",
    "4. Click **Load** or **Transform Data** (for Power Query)\n",
    "\n",
    "#### 🔷 Connecting to SQL Database\n",
    "\n",
    "1. Click **Get Data** → Select **SQL Server**\n",
    "2. Provide:\n",
    "\n",
    "   * **Server name**\n",
    "   * **Database name (optional)**\n",
    "   * Choose between **Import** or **DirectQuery**\n",
    "3. Enter credentials\n",
    "4. Load or transform\n",
    "\n",
    "#### 🔷 Connecting to a Web API or URL\n",
    "\n",
    "1. Click **Get Data** → **Web**\n",
    "2. Paste API endpoint or URL\n",
    "3. Authenticate if required\n",
    "4. Load or apply transformation in Power Query\n",
    "\n",
    "#### 🔷 Connecting to Cloud (e.g., SharePoint Folder)\n",
    "\n",
    "1. Click **Get Data** → **SharePoint Folder**\n",
    "2. Paste SharePoint URL\n",
    "3. Authenticate with organizational account\n",
    "4. Filter and transform data\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Summary\n",
    "\n",
    "| Topic                    | Key Points                            |\n",
    "| ------------------------ | ------------------------------------- |\n",
    "| Supported Sources        | Files, Databases, Cloud, APIs         |\n",
    "| Local vs Shared          | Local = isolated, Shared = reusable   |\n",
    "| Connectors               | Enable plug-and-play data integration |\n",
    "| Connecting to Excel & DB | Easy and guided via Get Data wizard   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887790df",
   "metadata": {},
   "source": [
    "## 🔶 3. Storage Modes in Power BI\n",
    "\n",
    "Power BI offers **three storage modes** to determine how data is stored, queried, and refreshed. Choosing the right storage mode affects **performance**, **data freshness**, and **query behavior**.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 1. **Import Mode** (Default)\n",
    "\n",
    "#### 🔹 How it works:\n",
    "\n",
    "* Data is **imported** and stored **in-memory** within Power BI.\n",
    "* Querying is extremely **fast**, as it uses **VertiPaq compression**.\n",
    "* Data is **refreshed on schedule** (not real-time).\n",
    "\n",
    "#### 🔹 Use Cases:\n",
    "\n",
    "* When **fast performance** is crucial.\n",
    "* Suitable for **small to medium datasets**.\n",
    "* When **data does not change frequently**.\n",
    "\n",
    "#### ✅ Advantages:\n",
    "\n",
    "* Blazing-fast performance\n",
    "* Full DAX support\n",
    "* Supports complex models and calculated tables\n",
    "\n",
    "#### ⚠️ Limitations:\n",
    "\n",
    "* Data can become stale (requires refresh)\n",
    "* Dataset size limit in Power BI Service (1 GB or more with premium)\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 2. **DirectQuery Mode**\n",
    "\n",
    "#### 🔹 How it works:\n",
    "\n",
    "* Power BI **does not import data**.\n",
    "* Queries are **sent directly to the source** each time you interact with the report.\n",
    "\n",
    "#### 🔹 Use Cases:\n",
    "\n",
    "* When **real-time or near-real-time** data is needed.\n",
    "* Datasets that are **too large to fit in memory**.\n",
    "* Use with **enterprise-grade databases** (e.g., SQL Server, Azure SQL, SAP HANA).\n",
    "\n",
    "#### ✅ Advantages:\n",
    "\n",
    "* Live, up-to-date data\n",
    "* No data duplication or memory usage\n",
    "* Good for frequently changing data\n",
    "\n",
    "#### ⚠️ Limitations:\n",
    "\n",
    "* Slower performance due to source round-trips\n",
    "* Limited DAX and transformation options\n",
    "* Dependent on source database performance\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 3. **Dual Mode**\n",
    "\n",
    "#### 🔹 How it works:\n",
    "\n",
    "* A table can act as both **Import** and **DirectQuery**.\n",
    "* Power BI decides contextually whether to use in-memory or direct query.\n",
    "\n",
    "#### 🔹 Use Cases:\n",
    "\n",
    "* Useful in **composite models** with fact and dimension tables.\n",
    "* Optimize performance **while keeping some data real-time**.\n",
    "\n",
    "#### ✅ Advantages:\n",
    "\n",
    "* Best of both worlds (performance + freshness)\n",
    "* Enables building scalable **composite models**\n",
    "* Can reduce load on the data source\n",
    "\n",
    "#### ⚠️ Limitations:\n",
    "\n",
    "* Requires advanced model design\n",
    "* Not all connectors support dual mode\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Choosing the Appropriate Mode: Quick Guide\n",
    "\n",
    "| Requirement                         | Recommended Mode       |\n",
    "| ----------------------------------- | ---------------------- |\n",
    "| Fast report performance             | Import                 |\n",
    "| Real-time or live data              | DirectQuery            |\n",
    "| Balance of performance & real-time  | Dual                   |\n",
    "| Large datasets with memory concerns | DirectQuery            |\n",
    "| Using multiple storage strategies   | Dual (Composite Model) |\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Summary Table\n",
    "\n",
    "| Mode            | Storage          | Performance  | Freshness               | Limits           |\n",
    "| --------------- | ---------------- | ------------ | ----------------------- | ---------------- |\n",
    "| **Import**      | In-memory        | ⚡ Fast       | ❌ Stale without refresh | Memory-limited   |\n",
    "| **DirectQuery** | Live from source | 🐢 Slower    | ✅ Real-time             | Source-dependent |\n",
    "| **Dual**        | Both             | ⚡ + 🐢 Mixed | ✅ + ❌ Mixed             | Flexible         |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3b23e5",
   "metadata": {},
   "source": [
    "## 🔶 4. Data Types in Power BI\n",
    "\n",
    "Understanding **data types** is critical when working with Power BI because incorrect data types can lead to **errors**, **wrong calculations**, and **unexpected behavior** during transformations and visualizations.\n",
    "\n",
    "Power BI offers **several fundamental data types**, each suited for specific kinds of data and operations.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 1. **Numeric Data Types**\n",
    "\n",
    "Used for **numbers** that can be calculated or aggregated.\n",
    "\n",
    "#### 🔸 Common Numeric Types:\n",
    "\n",
    "* **Decimal Number** – Fractional numbers (e.g., 3.14)\n",
    "* **Whole Number** – Integers (e.g., 42, -9)\n",
    "* **Currency** – Numbers with fixed decimal precision (e.g., ₹999.99)\n",
    "* **Percentage** – Stored as decimals, displayed as percentages (e.g., 0.75 = 75%)\n",
    "\n",
    "#### 🔹 Usage:\n",
    "\n",
    "* Useful for **SUM**, **AVERAGE**, **MIN**, **MAX**, **calculations**, etc.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 2. **Text (Unicode)**\n",
    "\n",
    "Text (also known as **String** or **Unicode**) is used to represent:\n",
    "\n",
    "* Names\n",
    "* IDs\n",
    "* Descriptions\n",
    "* Alphanumeric codes\n",
    "\n",
    "#### 🔹 Usage:\n",
    "\n",
    "* Cannot be aggregated\n",
    "* Useful for **categorical variables**, filtering, labels in visualizations\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 3. **Date/Time**\n",
    "\n",
    "Represents **dates**, **times**, or both.\n",
    "\n",
    "#### 🔸 Types:\n",
    "\n",
    "* **Date** – Only the date portion (e.g., 2025-08-07)\n",
    "* **Time** – Only the time portion (e.g., 13:45:00)\n",
    "* **Date/Time** – Combined (e.g., 2025-08-07 13:45:00)\n",
    "* **Date/Time/Timezone** – Includes time zone info\n",
    "* **Duration** – Represents a length of time (e.g., 2 days, 5 hours)\n",
    "\n",
    "#### 🔹 Usage:\n",
    "\n",
    "* Supports **time intelligence** (e.g., YTD, QTD, MTD)\n",
    "* Enables **filtering by time**, grouping by period, etc.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 4. **Logical (Boolean)**\n",
    "\n",
    "Holds **True/False** values only.\n",
    "\n",
    "#### 🔹 Usage:\n",
    "\n",
    "* For conditions\n",
    "* Used in filters, calculated columns, DAX expressions like:\n",
    "\n",
    "  ```DAX\n",
    "  IF([Profit] > 1000, TRUE, FALSE)\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 5. **Binary**\n",
    "\n",
    "Holds **binary objects**, such as:\n",
    "\n",
    "* Images\n",
    "* Files\n",
    "* Blobs (e.g., PDFs, DOCs, media)\n",
    "\n",
    "#### 🔹 Usage:\n",
    "\n",
    "* Rare in most standard reporting\n",
    "* Often used in **Power Query transformations** for file processing\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Why Data Types Matter\n",
    "\n",
    "| Reason              | Explanation                                            |\n",
    "| ------------------- | ------------------------------------------------------ |\n",
    "| **Performance**     | Correct types ensure optimized queries                 |\n",
    "| **Accuracy**        | Prevents logic errors in calculations                  |\n",
    "| **Memory Usage**    | Some types (e.g., decimals vs. integers) affect memory |\n",
    "| **Transformations** | Some transformations only apply to specific types      |\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Changing Data Types in Power Query\n",
    "\n",
    "1. Open Power Query Editor\n",
    "2. Select the column\n",
    "3. Use the data type icon (next to column name)\n",
    "4. Choose the appropriate type from dropdown\n",
    "\n",
    "⚠️ Always validate the values after converting data types.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Summary Table\n",
    "\n",
    "| Data Type     | Example          | Common Uses                 |\n",
    "| ------------- | ---------------- | --------------------------- |\n",
    "| **Numeric**   | 123, 45.6        | Math, KPIs, Aggregates      |\n",
    "| **Text**      | \"Sales\", \"India\" | Labels, Filters, Categories |\n",
    "| **Date/Time** | 2025-08-07 10:30 | Trends, Time intelligence   |\n",
    "| **Logical**   | TRUE, FALSE      | Filtering, Conditions       |\n",
    "| **Binary**    | \\[Binary]        | File content, Blobs         |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64063e0a",
   "metadata": {},
   "source": [
    "## 🔶 5. Data Transformation in Power Query\n",
    "\n",
    "### **Overview**\n",
    "\n",
    "Power Query is the primary ETL tool inside Power BI, enabling you to **connect, clean, reshape, and combine data** before loading it into the data model.\n",
    "The transformations applied in Power Query are recorded as a **sequence of steps** (Applied Steps) and executed in the M language.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Transformation Features**\n",
    "\n",
    "#### 1️⃣ Applied Steps Panel\n",
    "\n",
    "* Displays the sequence of transformations.\n",
    "* You can:\n",
    "\n",
    "  * Edit or modify any step.\n",
    "  * Delete a step.\n",
    "  * Rearrange steps if needed.\n",
    "* Helps in **tracking changes** and troubleshooting.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2️⃣ Column Management\n",
    "\n",
    "* **Remove Columns**: Delete unnecessary fields to reduce dataset size and improve performance.\n",
    "* **Choose Columns**: Select only required columns for analysis.\n",
    "* **Rename Columns**: Make column names meaningful.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3️⃣ Row Management\n",
    "\n",
    "* **Remove Rows**:\n",
    "\n",
    "  * Remove duplicates.\n",
    "  * Remove top/bottom rows.\n",
    "  * Remove blank rows.\n",
    "* **Filter Rows**:\n",
    "\n",
    "  * Filter out anomalies or incorrect data.\n",
    "  * Keep only specific values.\n",
    "\n",
    "---\n",
    "\n",
    "#### 4️⃣ Data Type Conversion\n",
    "\n",
    "* Automatic detection occurs, but **manual review is recommended** to:\n",
    "\n",
    "  * Avoid incorrect interpretations.\n",
    "  * Reduce memory usage.\n",
    "\n",
    "---\n",
    "\n",
    "#### 5️⃣ Data Profiling Tools\n",
    "\n",
    "* **Column Quality**: Shows percentage of valid, error, and empty values.\n",
    "* **Column Distribution**: Shows count of distinct and unique values.\n",
    "* **Column Profile**: Detailed stats (min, max, average, standard deviation, distribution chart).\n",
    "\n",
    "---\n",
    "\n",
    "#### 6️⃣ Combining Data\n",
    "\n",
    "* **Append Queries**: Stack tables with same structure (e.g., `Order2022` + `Order2023` → `Orders`).\n",
    "* **Merge Queries**: Join tables based on a common key (e.g., `Orders` + `OrderDetails` on `SalesOrderID`).\n",
    "\n",
    "---\n",
    "\n",
    "#### 7️⃣ Pivot & Unpivot\n",
    "\n",
    "* **Pivot**: Transform row values into columns.\n",
    "* **Unpivot**: Convert multiple columns into attribute-value pairs.\n",
    "\n",
    "---\n",
    "\n",
    "#### 8️⃣ Handling Errors & Anomalies\n",
    "\n",
    "* Detect anomalies with **Column Profile**.\n",
    "* Remove or replace incorrect values.\n",
    "* Keep data clean for accurate analysis.\n",
    "\n",
    "---\n",
    "\n",
    "### **Activities Done on the Given Dataset**\n",
    "\n",
    "#### 📂 Dataset Files\n",
    "\n",
    "* `Order2022.xlsx` (Past year orders)\n",
    "* `Order2023.xlsx` (Current year orders)\n",
    "* `OrderDetails.xlsx` (Details of each order)\n",
    "\n",
    "---\n",
    "\n",
    "#### 🔹 Step-by-Step Process\n",
    "\n",
    "1. **Import Datasets**\n",
    "\n",
    "   * Used `Get Data → Excel` for all three files.\n",
    "   * Selected **Transform Data** to open in Power Query.\n",
    "\n",
    "2. **Clean `OrderDetails` Table**\n",
    "\n",
    "   * Kept only `SalesOrderID`, `ProductID`, `OrderQty`, and `UnitPrice`.\n",
    "   * Removed unnecessary columns.\n",
    "\n",
    "3. **Profile Data**\n",
    "\n",
    "   * Enabled `Column Quality`, `Column Distribution`, and `Column Profile`.\n",
    "   * Checked:\n",
    "\n",
    "     * Distinct values.\n",
    "     * Unique values.\n",
    "     * Valid/Empty/Error counts.\n",
    "\n",
    "4. **Detect & Remove Anomalies**\n",
    "\n",
    "   * Checked `UnitPrice` min, max, mean.\n",
    "   * Identified **3 outliers** (possible data entry errors).\n",
    "   * Filtered them out.\n",
    "\n",
    "5. **Append Orders Data**\n",
    "\n",
    "   * Combined `Order2022` and `Order2023` into a new table `Orders`.\n",
    "\n",
    "6. **Merge with Order Details**\n",
    "\n",
    "   * Merged `Orders` and `OrderDetails` on `SalesOrderID` using **Inner Join**.\n",
    "   * Selected only `OrderDate` from `Orders` table.\n",
    "   * Renamed `Orders.OrderDate` → `OrderDate`.\n",
    "\n",
    "7. **Final Clean-up**\n",
    "\n",
    "   * Ensured correct data types.\n",
    "   * Verified no anomalies remained.\n",
    "   * Loaded into Power BI Data Model.\n",
    "\n",
    "---\n",
    "\n",
    "✅ **Outcome**:\n",
    "You now have a **clean, combined, and anomaly-free dataset** ready for accurate sales analysis in Power BI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbe1612",
   "metadata": {},
   "source": [
    "## 🔶 6. Data Loading in Power BI\n",
    "\n",
    "### **Overview**\n",
    "\n",
    "The **Load** step is the final stage of the ETL process in Power BI.\n",
    "Here, the transformed data is **made available for reporting and analysis** in the Data Model.\n",
    "\n",
    "---\n",
    "\n",
    "### **Ways to Load Data**\n",
    "\n",
    "#### 1️⃣ Load\n",
    "\n",
    "* Directly loads data into the **Data pane** in Power BI.\n",
    "* You can still **transform the data later** using Power Query.\n",
    "\n",
    "#### 2️⃣ Transform Data\n",
    "\n",
    "* Opens Power Query Editor **before loading**.\n",
    "* Allows:\n",
    "\n",
    "  * Data cleaning.\n",
    "  * Applying transformations.\n",
    "  * Removing unnecessary columns/rows.\n",
    "  * Handling anomalies.\n",
    "\n",
    "---\n",
    "\n",
    "### **Data Staging Area**\n",
    "\n",
    "* A **temporary storage location** between the **data source** and **data warehouse/report model**.\n",
    "* Useful when:\n",
    "\n",
    "  * Source tables are **not production-ready**.\n",
    "  * You need intermediate processing.\n",
    "* Helps **reduce load time** and improve performance.\n",
    "\n",
    "---\n",
    "\n",
    "### **Storage Modes Recap**\n",
    "\n",
    "When loading, choose **based on needs**:\n",
    "\n",
    "* **Import Mode**: Fast for static data, but increases file size.\n",
    "* **Direct Query**: Live connection, real-time updates, may affect performance.\n",
    "* **Dual Mode**: Hybrid approach for dimension tables.\n",
    "\n",
    "---\n",
    "\n",
    "### **Performance Considerations During Load**\n",
    "\n",
    "* **Filter & reduce data early** in transformation.\n",
    "* Avoid unnecessary columns & rows.\n",
    "* Schedule **resource-heavy transformations last** in the process.\n",
    "* Use **Reference Queries** for reusable logic.\n",
    "\n",
    "---\n",
    "\n",
    "### **Dataset Activities Related to Loading**\n",
    "\n",
    "1. **Orders Data**\n",
    "\n",
    "   * `Order2022` + `Order2023` were **appended** in Power Query before loading.\n",
    "   * The combined table was **named `Orders`** and kept ready for merging.\n",
    "\n",
    "2. **Merge Operation**\n",
    "\n",
    "   * `Orders` merged with `OrderDetails` using **Inner Join**.\n",
    "   * Only relevant column (`OrderDate`) brought in from `Orders`.\n",
    "\n",
    "3. **Final Load**\n",
    "\n",
    "   * Verified data types.\n",
    "   * Checked row counts after anomaly removal.\n",
    "   * Loaded clean dataset to **Data View** in Power BI.\n",
    "\n",
    "---\n",
    "\n",
    "✅ **Outcome**:\n",
    "Data is **optimized, staged, and loaded** for reporting, ensuring:\n",
    "\n",
    "* Faster visuals.\n",
    "* Reliable calculations.\n",
    "* Easy scalability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf81e09",
   "metadata": {},
   "source": [
    "## 🔶 7. Data Profiling in Power BI\n",
    "\n",
    "### **Overview**\n",
    "\n",
    "Data profiling is the process of **examining the content and structure** of your dataset before analysis.\n",
    "It helps you:\n",
    "\n",
    "* Understand **data quality**.\n",
    "* Detect **errors, anomalies, and missing values**.\n",
    "* Decide on necessary transformations.\n",
    "\n",
    "In Power BI, data profiling is done inside **Power Query Editor** using three main tools.\n",
    "\n",
    "---\n",
    "\n",
    "### **1️⃣ Column Quality**\n",
    "\n",
    "* Shows the **percentage of**:\n",
    "\n",
    "  * **Valid** values → data that follows the column’s rules.\n",
    "  * **Error** values → invalid data types or failed conversions.\n",
    "  * **Empty** values → missing data.\n",
    "* Helps spot:\n",
    "\n",
    "  * Null fields.\n",
    "  * Data import errors.\n",
    "  * Formatting issues.\n",
    "\n",
    "📍 **Example from dataset**:\n",
    "In `OrderDetails`, we checked for empty rows in **ProductID** and **UnitPrice** to ensure no missing values were loaded.\n",
    "\n",
    "---\n",
    "\n",
    "### **2️⃣ Column Distribution**\n",
    "\n",
    "* Displays **unique** and **distinct** value counts:\n",
    "\n",
    "  * **Distinct values** → total number of different values in the column.\n",
    "  * **Unique values** → values that appear **only once** in the dataset.\n",
    "* Shows **frequency distribution** as a histogram.\n",
    "\n",
    "📍 **Example from dataset**:\n",
    "We used this to see **UnitPrice** distribution and noticed **3 outlier prices** far from the normal range.\n",
    "\n",
    "---\n",
    "\n",
    "### **3️⃣ Column Profile**\n",
    "\n",
    "* Provides **detailed statistics** for a selected column:\n",
    "\n",
    "  * Minimum, Maximum.\n",
    "  * Average (Mean).\n",
    "  * Standard Deviation.\n",
    "  * Mode (Most Frequent).\n",
    "  * Value Distribution chart.\n",
    "* Useful for detecting **anomalies**.\n",
    "\n",
    "📍 **Example from dataset**:\n",
    "For `UnitPrice`:\n",
    "\n",
    "* **Min**: Normal low value.\n",
    "* **Max**: Extremely high outlier.\n",
    "* **Mean**: Skewed due to anomalies.\n",
    "* Identified **3 incorrect entries** → removed using **filter and uncheck** in column filter.\n",
    "\n",
    "---\n",
    "\n",
    "### **Steps to Use Data Profiling Tools**\n",
    "\n",
    "1. Open **Power Query Editor** → **View Tab**.\n",
    "2. Enable:\n",
    "\n",
    "   * ✅ Column Quality.\n",
    "   * ✅ Column Distribution.\n",
    "   * ✅ Column Profile.\n",
    "3. Use these insights to:\n",
    "\n",
    "   * Remove anomalies.\n",
    "   * Correct invalid data.\n",
    "   * Handle missing values.\n",
    "\n",
    "---\n",
    "\n",
    "### **Dataset Activity Summary for Profiling**\n",
    "\n",
    "1. **Removed unnecessary columns** in `OrderDetails` (kept `SalesOrderID`, `ProductID`, `OrderQty`, `UnitPrice`).\n",
    "2. Enabled **all 3 profiling tools**.\n",
    "3. Checked:\n",
    "\n",
    "   * **Valid/Error/Empty** values (Column Quality).\n",
    "   * **Distinct & Unique counts** (Column Distribution).\n",
    "   * **Min/Max/Mean** values (Column Profile).\n",
    "4. **Detected 3 anomalies** in `UnitPrice` and removed them.\n",
    "5. Confirmed **row count** after cleanup before merging.\n",
    "\n",
    "---\n",
    "\n",
    "✅ **Outcome**:\n",
    "Data was **cleaned and verified** before loading, ensuring:\n",
    "\n",
    "* No invalid or missing critical fields.\n",
    "* Correct numerical ranges.\n",
    "* Higher accuracy in reports."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75049d4c",
   "metadata": {},
   "source": [
    "## 🔶 8. Combining Tables: Append & Merge in Power BI\n",
    "\n",
    "### **Overview**\n",
    "\n",
    "In Power BI, you often need to **combine data from multiple sources** into a single dataset.\n",
    "Two main methods:\n",
    "\n",
    "1. **Append Queries** → Stack tables vertically.\n",
    "2. **Merge Queries** → Join tables horizontally based on a common key.\n",
    "\n",
    "---\n",
    "\n",
    "## **1️⃣ Append Queries**\n",
    "\n",
    "**Purpose:**\n",
    "\n",
    "* Used when tables have the **same structure** (same columns & data types).\n",
    "* Adds rows from one table to another.\n",
    "\n",
    "**Steps in Power Query:**\n",
    "\n",
    "1. Home → **Append Queries** (or **Append Queries as New** to keep original tables).\n",
    "2. Select two or more tables to append.\n",
    "3. Ensure column names & data types match.\n",
    "\n",
    "📍 **Example from Dataset:**\n",
    "\n",
    "* **Tables:** `Order2022` and `Order2023`.\n",
    "* **Why Append?** → Both store the same order data for different years.\n",
    "* **Action Taken:**\n",
    "\n",
    "  * Appended them into a new query named **Orders**.\n",
    "  * Verified column names, row count, and appended values.\n",
    "\n",
    "---\n",
    "\n",
    "## **2️⃣ Merge Queries**\n",
    "\n",
    "**Purpose:**\n",
    "\n",
    "* Combines columns from two tables based on **matching values** in a key column.\n",
    "* Similar to SQL joins.\n",
    "\n",
    "**Steps in Power Query:**\n",
    "\n",
    "1. Select a query → Home → **Merge Queries**.\n",
    "2. Choose the other table to merge with.\n",
    "3. Select the **join key(s)** in both tables.\n",
    "4. Pick **Join Kind** from dropdown.\n",
    "5. Expand merged table to select only needed columns.\n",
    "\n",
    "📍 **Example from Dataset:**\n",
    "\n",
    "* **Tables:** `OrderDetails` and `Orders`.\n",
    "* **Common Key:** `SalesOrderID`.\n",
    "* **Join Type:** **Inner Join** → Only keep rows with matching SalesOrderID in both tables.\n",
    "* **Action Taken:**\n",
    "\n",
    "  * Merged `OrderDetails` (left) with `Orders` (right).\n",
    "  * Expanded the merged table and selected only the `OrderDate` column.\n",
    "  * Renamed `Orders.OrderDate` → `OrderDate`.\n",
    "\n",
    "---\n",
    "\n",
    "## **3️⃣ Join Types in Power BI**\n",
    "\n",
    "| Join Type       | Description                                                  |\n",
    "| --------------- | ------------------------------------------------------------ |\n",
    "| **Inner Join**  | Keeps only matching rows in both tables.                     |\n",
    "| **Left Outer**  | All rows from left table + matching rows from right.         |\n",
    "| **Right Outer** | All rows from right table + matching rows from left.         |\n",
    "| **Full Outer**  | All rows from both tables, matching where possible.          |\n",
    "| **Anti Join**   | Returns rows that **don’t** have matches in the other table. |\n",
    "\n",
    "📌 In our project: **Inner Join** was used because we only wanted matching sales records with full order info.\n",
    "\n",
    "---\n",
    "\n",
    "## **4️⃣ Best Practices**\n",
    "\n",
    "* **Use Append** when combining **historical data files** with identical structure.\n",
    "* **Use Merge** when adding **related columns** from another table.\n",
    "* Always check:\n",
    "\n",
    "  * **Column names & data types** before append.\n",
    "  * **Join keys** are correct and unique when possible.\n",
    "* After merge, expand only the required columns to improve performance.\n",
    "\n",
    "---\n",
    "\n",
    "## **Dataset Activity Summary for Combining Tables**\n",
    "\n",
    "1. **Appended** `Order2022` + `Order2023` → new table **Orders**.\n",
    "2. Verified row count & structure after append.\n",
    "3. **Merged** `OrderDetails` with `Orders` on `SalesOrderID`.\n",
    "4. Chose **Inner Join** → only matching sales included.\n",
    "5. Expanded to keep **OrderDate** column only.\n",
    "6. Renamed to `OrderDate` and finalized cleaned dataset.\n",
    "\n",
    "---\n",
    "\n",
    "✅ **Outcome:**\n",
    "We successfully combined sales details with their corresponding order dates, after cleaning the data. This gave us:\n",
    "\n",
    "* One **master dataset** with historical + current sales data.\n",
    "* Correctly matched sales and order info.\n",
    "* A ready-to-use table for reporting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c486af",
   "metadata": {},
   "source": [
    "## 🔶 9. Reference Queries & Dataflows in Power BI\n",
    "\n",
    "---\n",
    "\n",
    "### **1️⃣ Reference Queries**\n",
    "\n",
    "#### **What is a Reference Query?**\n",
    "\n",
    "* A **reference query** is a new query that **references the output** of another query instead of duplicating it.\n",
    "* Any change in the **original query** automatically flows to the referenced query.\n",
    "* Helps create **modular transformations** and **reuse logic**.\n",
    "\n",
    "#### **Why use Reference Queries?**\n",
    "\n",
    "* **Reusability**: One clean, base query can be reused in multiple transformations.\n",
    "* **Efficiency**: Avoids repeating the same steps on multiple queries.\n",
    "* **Scalability**: Easy to maintain — change the base query once, and all references update.\n",
    "\n",
    "#### **How to create a Reference Query:**\n",
    "\n",
    "1. In **Power Query**, right-click the base query.\n",
    "2. Select **Reference** (not Duplicate).\n",
    "3. Apply further transformations on the reference query as needed.\n",
    "\n",
    "---\n",
    "\n",
    "📍 **Example from Dataset:**\n",
    "\n",
    "* Suppose we have a clean **Orders** query (after appending 2022 & 2023 data).\n",
    "* We create:\n",
    "\n",
    "  * `Orders` → Base query with all order data.\n",
    "  * `Orders_Filtered` (Reference Query) → Only orders from a specific territory or date range.\n",
    "* Any correction to the **Orders** query (e.g., fixing data types) automatically applies to **Orders\\_Filtered**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Best Practices for Reference Queries**\n",
    "\n",
    "* Keep base queries **lightweight and clean** — only essential transformations.\n",
    "* Use references instead of copies to ensure consistency.\n",
    "* Avoid **too many nested references** to prevent slow refresh.\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "### **2️⃣ Dataflows**\n",
    "\n",
    "#### **What is a Dataflow?**\n",
    "\n",
    "* A **dataflow** is a cloud-based ETL process in the **Power BI Service**.\n",
    "* Allows **self-service data preparation** in the cloud.\n",
    "* Stores data in **Azure Data Lake**.\n",
    "* Can be used by multiple datasets and reports.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Benefits of Dataflows**\n",
    "\n",
    "* **Centralized data preparation** for an entire organization.\n",
    "* **Reusable data entities** across multiple Power BI reports.\n",
    "* Can connect to **both cloud and on-premises** data sources.\n",
    "* Helps in **reducing redundancy** — transformations are done once.\n",
    "\n",
    "---\n",
    "\n",
    "#### **When to use Dataflows vs Reference Queries**\n",
    "\n",
    "| **Scenario**                                               | **Use Reference Queries** | **Use Dataflows**   |\n",
    "| ---------------------------------------------------------- | ------------------------- | ------------------- |\n",
    "| You’re working within a **single PBIX file**               | ✅ Yes                     | ❌ Not needed        |\n",
    "| You need the same transformed data in **multiple reports** | ❌ No                      | ✅ Yes               |\n",
    "| You want cloud-based refresh and storage                   | ❌ No                      | ✅ Yes               |\n",
    "| You need lightweight, in-memory transformations            | ✅ Yes                     | ❌ Not the main goal |\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "📍 **Example Application (From Our Dataset)**\n",
    "\n",
    "* **In Power BI Desktop**:\n",
    "\n",
    "  * Used **Reference Query** to create variations of `OrderDetails` without touching the original.\n",
    "* **In Power BI Service**:\n",
    "\n",
    "  * Could publish a cleaned version of `Orders` + `OrderDetails` as a **Dataflow**.\n",
    "  * Other analysts can connect directly to this cleaned dataset for reporting.\n",
    "\n",
    "---\n",
    "\n",
    "### **Best Practices for Dataflows**\n",
    "\n",
    "* Use **descriptive entity names** so others know what the dataflow contains.\n",
    "* Schedule **refreshes during off-peak hours** to reduce resource strain.\n",
    "* Document transformations in the dataflow for team transparency.\n",
    "* Avoid excessive complex joins inside dataflows — optimize upstream if possible.\n",
    "\n",
    "---\n",
    "\n",
    "### **Performance Considerations**\n",
    "\n",
    "* **Reference Queries** → Slightly slower refresh if referencing many other queries, but still good for in-file reuse.\n",
    "* **Dataflows** → Can speed up report refresh times because transformations happen before loading to the report.\n",
    "\n",
    "---\n",
    "\n",
    "✅ **Outcome of Learning:**\n",
    "After mastering **Reference Queries** and **Dataflows**, you can:\n",
    "\n",
    "* Build cleaner, reusable, and maintainable data transformation pipelines.\n",
    "* Centralize ETL logic for organization-wide use.\n",
    "* Reduce duplication of work in Power BI projects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb028166",
   "metadata": {},
   "source": [
    "## 🔶 10. Data Profiling in Power BI\n",
    "\n",
    "---\n",
    "\n",
    "### **1️⃣ What is Data Profiling?**\n",
    "\n",
    "Data profiling is the process of **analyzing your dataset to understand its structure, quality, and potential issues** before performing transformations or analysis.\n",
    "\n",
    "It helps in:\n",
    "\n",
    "* **Detecting anomalies** (e.g., unusually high prices)\n",
    "* **Identifying missing or invalid data**\n",
    "* **Ensuring data types are correct**\n",
    "* **Understanding distribution & patterns**\n",
    "\n",
    "---\n",
    "\n",
    "### **2️⃣ Data Profiling Tools in Power Query**\n",
    "\n",
    "Power BI provides **three main profiling options** in **Power Query Editor** under the **View** tab:\n",
    "\n",
    "| **Tool**                | **Purpose**                                                                |\n",
    "| ----------------------- | -------------------------------------------------------------------------- |\n",
    "| **Column Quality**      | Shows % of valid, error, and empty values.                                 |\n",
    "| **Column Distribution** | Shows distinct & unique values count.                                      |\n",
    "| **Column Profile**      | Detailed stats (Min, Max, Mean, Std Dev, Mode) + value distribution chart. |\n",
    "\n",
    "---\n",
    "\n",
    "### **3️⃣ How to Enable Data Profiling**\n",
    "\n",
    "In **Power Query Editor**:\n",
    "\n",
    "1. Go to **View** tab → **Data Preview** group.\n",
    "2. Check:\n",
    "\n",
    "   * ✅ Column Quality\n",
    "   * ✅ Column Distribution\n",
    "   * ✅ Column Profile (for detailed view)\n",
    "3. Make sure **\"Column profiling based on entire dataset\"** is selected for accurate results.\n",
    "\n",
    "---\n",
    "\n",
    "### **4️⃣ Example: Activity from Dataset (OrderDetails Table)**\n",
    "\n",
    "#### **Step 1: Import Data**\n",
    "\n",
    "* Files used:\n",
    "\n",
    "  * `Order2022.xlsx`\n",
    "  * `Order2023.xlsx`\n",
    "  * `OrderDetails.xlsx`\n",
    "\n",
    "#### **Step 2: Keep Required Columns**\n",
    "\n",
    "In `OrderDetails`, keep only:\n",
    "\n",
    "* `SalesOrderID`\n",
    "* `ProductID`\n",
    "* `OrderQty`\n",
    "* `UnitPrice`\n",
    "\n",
    "#### **Step 3: Enable Profiling**\n",
    "\n",
    "* Turn on **Column Quality**, **Column Distribution**, and **Column Profile**.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 4: Detect Anomalies in `UnitPrice`**\n",
    "\n",
    "* View **Column Profile** for `UnitPrice`.\n",
    "* Found:\n",
    "\n",
    "  * **Min:** normal value (e.g., 2.50)\n",
    "  * **Max:** unusually high value (e.g., 9999.99)\n",
    "  * **Mean:** far from normal range due to outliers.\n",
    "* Observation: **3 outlier rows** were likely **typos**.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 5: Remove Anomalies**\n",
    "\n",
    "1. Click **Filter dropdown** in `UnitPrice`.\n",
    "2. Uncheck the extreme anomaly values.\n",
    "3. This ensures **accurate calculations** in later steps.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 6: Results After Cleaning**\n",
    "\n",
    "* `UnitPrice` → No more anomalies.\n",
    "* **Distinct values:** 27\n",
    "* **Unique values:** 6\n",
    "* Total rows reduced from **999** to **996**.\n",
    "\n",
    "---\n",
    "\n",
    "### **5️⃣ Impact of Removing Anomalies**\n",
    "\n",
    "* **Data Integrity** → No fake high-value sales.\n",
    "* **Improved Accuracy** → Averages & totals reflect reality.\n",
    "* **Better Decision Making** → Sales reports are trustworthy.\n",
    "\n",
    "---\n",
    "\n",
    "### **6️⃣ Best Practices for Data Profiling**\n",
    "\n",
    "* Always **profile before transforming** — garbage in, garbage out.\n",
    "* Check for **nulls, errors, and duplicates**.\n",
    "* Document detected anomalies and how you handled them.\n",
    "* Re-run profiling after major transformations.\n",
    "\n",
    "---\n",
    "\n",
    "✅ **Outcome of Learning:**\n",
    "After mastering Data Profiling in Power BI, you can:\n",
    "\n",
    "* Spot and fix data issues early.\n",
    "* Ensure transformations are applied to clean, reliable data.\n",
    "* Prevent misleading results in dashboards and reports."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e14cf2",
   "metadata": {},
   "source": [
    "## 🔶 11. Combining Queries (Append & Merge) in Power BI\n",
    "\n",
    "---\n",
    "\n",
    "### **1️⃣ Introduction**\n",
    "\n",
    "When working with multiple datasets in Power BI, you often need to **combine them** so you can:\n",
    "\n",
    "* Analyze them together\n",
    "* Build relationships\n",
    "* Create a unified report\n",
    "\n",
    "Two main techniques in **Power Query**:\n",
    "\n",
    "1. **Append Queries** → Stack datasets on top of each other (union).\n",
    "2. **Merge Queries** → Join datasets side-by-side based on a common key.\n",
    "\n",
    "---\n",
    "\n",
    "## **A. Append Queries**\n",
    "\n",
    "**Purpose**: Used when multiple datasets have **same structure (columns)** and you want to combine their rows.\n",
    "\n",
    "---\n",
    "\n",
    "### **Steps in Our Project**\n",
    "\n",
    "**Files Used**:\n",
    "\n",
    "* `Order2022.xlsx`\n",
    "* `Order2023.xlsx`\n",
    "\n",
    "#### **Step 1: Load Both Tables**\n",
    "\n",
    "* Import both files into **Power Query**.\n",
    "* Verify they have **identical column names** and structure.\n",
    "\n",
    "#### **Step 2: Append**\n",
    "\n",
    "1. In **Home tab** → Click **Append Queries as New**.\n",
    "2. Select:\n",
    "\n",
    "   * **First table**: `Order2022`\n",
    "   * **Second table**: `Order2023`\n",
    "3. Click OK → A **new table** is created containing all rows from both years.\n",
    "\n",
    "#### **Step 3: Rename**\n",
    "\n",
    "* Name this combined table: **`Orders`**.\n",
    "\n",
    "---\n",
    "\n",
    "**📌 Result After Append**\n",
    "\n",
    "* A single `Orders` table with **all 2022 & 2023 sales orders**.\n",
    "* Same columns, more rows.\n",
    "* Used later for merging with `OrderDetails`.\n",
    "\n",
    "---\n",
    "\n",
    "## **B. Merge Queries**\n",
    "\n",
    "**Purpose**: Used when you want to **combine related columns from two tables** based on a common column (**key**).\n",
    "\n",
    "---\n",
    "\n",
    "### **Steps in Our Project**\n",
    "\n",
    "**Tables Used**:\n",
    "\n",
    "* `OrderDetails` (cleaned version with anomalies removed)\n",
    "* `Orders` (appended table from above)\n",
    "\n",
    "#### **Step 1: Select Table to Merge**\n",
    "\n",
    "* Select `OrderDetails` in the Queries pane.\n",
    "* Click **Merge Queries** from the **Home** tab.\n",
    "\n",
    "#### **Step 2: Choose Table & Match Column**\n",
    "\n",
    "* **First table**: `OrderDetails`\n",
    "* **Second table**: `Orders`\n",
    "* **Common key**: `SalesOrderID` in both tables.\n",
    "\n",
    "#### **Step 3: Select Join Type**\n",
    "\n",
    "* **Inner Join** → Keeps **only matching rows** between `OrderDetails` and `Orders`.\n",
    "\n",
    "#### **Step 4: Expand Columns**\n",
    "\n",
    "* After merging, a new column (`Orders`) appears.\n",
    "* Click **Expand** icon → Select only `OrderDate` column.\n",
    "* Rename to `OrderDate`.\n",
    "\n",
    "---\n",
    "\n",
    "**📌 Result After Merge**\n",
    "\n",
    "* `OrderDetails` now contains:\n",
    "\n",
    "  * `SalesOrderID`\n",
    "  * `ProductID`\n",
    "  * `OrderQty`\n",
    "  * `UnitPrice`\n",
    "  * `OrderDate` (from merged `Orders` table)\n",
    "\n",
    "---\n",
    "\n",
    "### **3️⃣ Why We Used These Methods**\n",
    "\n",
    "* **Append**: To consolidate multiple years of data into one table.\n",
    "* **Merge**: To link `OrderDetails` with `OrderDate` information from the `Orders` table.\n",
    "\n",
    "---\n",
    "\n",
    "### **4️⃣ Best Practices**\n",
    "\n",
    "* Before appending → ensure same column names & data types.\n",
    "* Before merging → ensure join key values match (avoid mismatched data types).\n",
    "* Choose **Inner Join** when you only need matching records.\n",
    "* Use **Left Outer Join** if you want to keep all records from the first table.\n",
    "\n",
    "---\n",
    "\n",
    "✅ **Outcome of Learning:**\n",
    "After mastering Append & Merge in Power BI, you can:\n",
    "\n",
    "* Combine datasets efficiently.\n",
    "* Link related tables for enriched analysis.\n",
    "* Build a **single source of truth** for your reports."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35c2f9c",
   "metadata": {},
   "source": [
    "## 🔶 12. Advanced ETL Features in Power BI\n",
    "\n",
    "---\n",
    "\n",
    "### **1️⃣ Reference Queries**\n",
    "\n",
    "**Definition**\n",
    "A **Reference Query** is a query that uses the output of another query as its starting point.\n",
    "It **does not duplicate** the data — it simply *references* the original query.\n",
    "\n",
    "---\n",
    "\n",
    "**📌 Why Use Reference Queries?**\n",
    "\n",
    "* **Reusability** → If you transform a table once, you can reuse it in other queries without redoing transformations.\n",
    "* **Consistency** → All queries update together if the source changes.\n",
    "* **Efficiency** → Reduces manual work and avoids maintaining multiple copies.\n",
    "\n",
    "---\n",
    "\n",
    "**💡 Example from Our Dataset**\n",
    "\n",
    "1. We created the `Orders` table by appending 2022 & 2023 orders.\n",
    "2. If we wanted a **filtered version** of `Orders` (e.g., only 2023 data), we could:\n",
    "\n",
    "   * Right-click `Orders` → **Reference**\n",
    "   * Apply filter for `OrderDate` = 2023.\n",
    "3. This keeps the `Orders` table intact and creates a dependent query.\n",
    "\n",
    "---\n",
    "\n",
    "**⚠️ Note on Performance**\n",
    "\n",
    "* Reference queries can slow refresh if the base query is large — because refreshing one reference query refreshes all queries it depends on.\n",
    "\n",
    "---\n",
    "\n",
    "### **2️⃣ Query Parameters**\n",
    "\n",
    "**Definition**\n",
    "A **Query Parameter** is a dynamic value you can pass into a query, making it flexible without hardcoding values.\n",
    "\n",
    "---\n",
    "\n",
    "**📌 Why Use Query Parameters?**\n",
    "\n",
    "* Filter datasets by date, category, or region without editing queries.\n",
    "* Reuse the same query logic for different conditions.\n",
    "* Improve performance by only loading needed data.\n",
    "\n",
    "---\n",
    "\n",
    "**💡 Example from Our Dataset**\n",
    "\n",
    "* Suppose we want to load orders **only from a specific year**.\n",
    "* Create a parameter: `YearFilter` = 2023.\n",
    "* In the `Orders` query, filter `OrderDate` → Year = `YearFilter`.\n",
    "* Now changing the parameter changes the filtered year everywhere it’s used.\n",
    "\n",
    "---\n",
    "\n",
    "### **3️⃣ Advanced Editor**\n",
    "\n",
    "**Definition**\n",
    "The **Advanced Editor** in Power Query lets you see and modify the **M language** code generated by your transformations.\n",
    "\n",
    "---\n",
    "\n",
    "**📌 Why Use It?**\n",
    "\n",
    "* Apply transformations that are not directly available in the UI.\n",
    "* Combine steps into more efficient code.\n",
    "* Copy transformations between queries.\n",
    "\n",
    "---\n",
    "\n",
    "**💡 Example from Our Dataset**\n",
    "When we removed anomalies in `UnitPrice`:\n",
    "\n",
    "```m\n",
    "= Table.SelectRows(#\"Changed Type\", each [UnitPrice] <> 0 and [UnitPrice] < 10000)\n",
    "```\n",
    "\n",
    "We could manually adjust this in **Advanced Editor** to change the anomaly threshold.\n",
    "\n",
    "---\n",
    "\n",
    "### **4️⃣ Global Options for Files**\n",
    "\n",
    "In **File → Options and Settings → Options**:\n",
    "\n",
    "* Set default **privacy levels** for data sources.\n",
    "* Adjust **data load settings** for better performance.\n",
    "* Configure **default column type detection**.\n",
    "\n",
    "---\n",
    "\n",
    "### **5️⃣ Activities from Your Project Using These Features**\n",
    "\n",
    "* **Reference Query**: Could be used if we created variations of `OrderDetails` (e.g., filtered by territory).\n",
    "* **Parameter**: Could control which year’s orders to load from `Orders`.\n",
    "* **Advanced Editor**: We could modify the anomaly detection logic directly in M code.\n",
    "\n",
    "---\n",
    "\n",
    "✅ **Outcome of Learning**\n",
    "After this section, you can:\n",
    "\n",
    "* Reuse and maintain queries efficiently with **Reference Queries**.\n",
    "* Make queries dynamic using **Parameters**.\n",
    "* Fine-tune and optimize ETL logic using **Advanced Editor**.\n",
    "* Configure Power BI to match your workflow with **Global Options**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377fa9df",
   "metadata": {},
   "source": [
    "### 🔶 **13. M Language Basics**\n",
    "\n",
    "---\n",
    "\n",
    "#### **1️⃣ What is M Language?**\n",
    "\n",
    "* M is the **formula language** behind Power Query.\n",
    "* Every transformation you perform in Power Query generates M code in the background.\n",
    "* You can view and edit it in the **Advanced Editor**.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2️⃣ Where to Find It**\n",
    "\n",
    "* Go to **Home → Advanced Editor** in Power Query.\n",
    "* The code structure looks like:\n",
    "\n",
    "```m\n",
    "let\n",
    "    Source = Excel.Workbook(File.Contents(\"C:\\Data\\Orders.xlsx\"), null, true),\n",
    "    ChangedType = Table.TransformColumnTypes(Source,{{\"OrderDate\", type date}})\n",
    "in\n",
    "    ChangedType\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **3️⃣ Key Characteristics**\n",
    "\n",
    "* **Case-sensitive** → `Table.TransformColumnTypes` ≠ `table.transformcolumntypes`\n",
    "* Steps are **named** and executed sequentially.\n",
    "* Starts with **let** block, ends with **in** block.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4️⃣ Why Use M Language?**\n",
    "\n",
    "* For transformations **not available in the UI**.\n",
    "* To write **efficient transformations** with fewer steps.\n",
    "* To copy transformations between queries.\n",
    "* To create **dynamic, parameter-driven queries**.\n",
    "\n",
    "---\n",
    "\n",
    "#### **5️⃣ Common M Functions**\n",
    "\n",
    "| Function                     | Purpose             | Example                                                                  |\n",
    "| ---------------------------- | ------------------- | ------------------------------------------------------------------------ |\n",
    "| `Table.SelectRows`           | Filters rows        | `Table.SelectRows(Orders, each [Year] = 2023)`                           |\n",
    "| `Table.RemoveColumns`        | Removes columns     | `Table.RemoveColumns(Orders,{\"Column1\"})`                                |\n",
    "| `Table.TransformColumnTypes` | Change column types | `Table.TransformColumnTypes(Orders,{{\"Price\", type number}})`            |\n",
    "| `Table.Combine`              | Append tables       | `Table.Combine({Orders2022, Orders2023})`                                |\n",
    "| `Table.Join`                 | Merge tables        | `Table.Join(OrderDetails, \"OrderID\", Orders, \"OrderID\", JoinKind.Inner)` |\n",
    "\n",
    "---\n",
    "\n",
    "#### **6️⃣ Example from Our Dataset**\n",
    "\n",
    "When removing anomalies in `UnitPrice`:\n",
    "\n",
    "```m\n",
    "FilteredRows = Table.SelectRows(#\"Changed Type\", \n",
    "    each [UnitPrice] <> 0 and [UnitPrice] < 10000)\n",
    "```\n",
    "\n",
    "* This keeps only rows with a **UnitPrice** less than 10,000 and not equal to zero.\n",
    "\n",
    "---\n",
    "\n",
    "#### **7️⃣ Best Practices for M Language**\n",
    "\n",
    "* Use **descriptive step names** for easier maintenance.\n",
    "* Minimize the number of applied steps (combine where possible).\n",
    "* Leverage parameters for **dynamic filters**.\n",
    "* Keep original source query untouched — use **reference queries**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b11590",
   "metadata": {},
   "source": [
    "## 🔶 **14. Common Data Errors in Power BI**\n",
    "\n",
    "---\n",
    "\n",
    "### **1️⃣ Why Data Errors Matter**\n",
    "\n",
    "Data errors can distort insights, lead to wrong decisions, and cause performance issues.\n",
    "In Power BI, identifying and fixing them in the **Transform (T)** phase is essential before loading data.\n",
    "\n",
    "---\n",
    "\n",
    "### **2️⃣ Common Types of Data Errors**\n",
    "\n",
    "#### **A. Missing / Null Values**\n",
    "\n",
    "* **Definition:** Fields with no data (empty cells).\n",
    "* **Causes:**\n",
    "\n",
    "  * Data not collected at the source.\n",
    "  * Incomplete imports.\n",
    "  * Incorrect joins (unmatched rows).\n",
    "* **Identification in Power Query:**\n",
    "\n",
    "  * Enable **Column Quality** in *View* tab → shows percentage of empty values.\n",
    "* **Fixes:**\n",
    "\n",
    "  * Replace nulls with default values.\n",
    "  * Remove rows with nulls.\n",
    "  * Fill down/up (propagate values).\n",
    "\n",
    "---\n",
    "\n",
    "#### **B. Duplicate Rows**\n",
    "\n",
    "* **Definition:** Same record appearing more than once.\n",
    "* **Causes:**\n",
    "\n",
    "  * Multiple imports of the same data.\n",
    "  * System duplication during ETL.\n",
    "* **Identification:**\n",
    "\n",
    "  * *Home → Remove Rows → Remove Duplicates* in Power Query.\n",
    "* **Fixes:**\n",
    "\n",
    "  * Remove duplicates based on **all columns** or **specific keys**.\n",
    "  * For example, `SalesOrderID` can be used as a key.\n",
    "\n",
    "---\n",
    "\n",
    "#### **C. Inconsistent Data Types**\n",
    "\n",
    "* **Definition:** Wrong format in a column (e.g., text in a numeric column).\n",
    "* **Causes:**\n",
    "\n",
    "  * Manual entry errors.\n",
    "  * Mismatched formats between sources.\n",
    "* **Identification:**\n",
    "\n",
    "  * Data type icons in column headers.\n",
    "  * Errors shown in **Column Quality**.\n",
    "* **Fixes:**\n",
    "\n",
    "  * Convert data types manually.\n",
    "  * Use **Detect Data Type** carefully and review.\n",
    "\n",
    "---\n",
    "\n",
    "#### **D. Data Entry Anomalies (Outliers)**\n",
    "\n",
    "* **Definition:** Values that are significantly higher/lower than expected.\n",
    "* **Example in Our Dataset:**\n",
    "  In `UnitPrice` column, 3 rows had unusually high or low prices due to typos.\n",
    "* **Identification:**\n",
    "\n",
    "  * Use **Column Profile** to view min, max, average.\n",
    "  * Compare with expected business ranges.\n",
    "* **Fixes:**\n",
    "\n",
    "  * Filter out anomaly values.\n",
    "  * Replace with correct values if known.\n",
    "\n",
    "---\n",
    "\n",
    "#### **E. Import Errors**\n",
    "\n",
    "* **Definition:** Rows fail to load correctly during import.\n",
    "* **Causes:**\n",
    "\n",
    "  * Schema mismatches between files.\n",
    "  * Corrupt source files.\n",
    "* **Fixes:**\n",
    "\n",
    "  * Use *Keep Errors* or *Remove Errors* in Power Query.\n",
    "  * Review data source structure.\n",
    "\n",
    "---\n",
    "\n",
    "### **3️⃣ Dataset Activity Example**\n",
    "\n",
    "In our **OrderDetails** table:\n",
    "\n",
    "1. **Identified anomalies** in `UnitPrice` using *Column Profile*:\n",
    "\n",
    "   * Min: **\\$0.00** (invalid)\n",
    "   * Max: **\\$99,999.00** (typo)\n",
    "   * Avg: \\~**\\$356.00**\n",
    "2. **Filtered out** rows where:\n",
    "\n",
    "   * `UnitPrice = 0` OR\n",
    "   * `UnitPrice > 10,000`\n",
    "3. Verified **Column Quality** → 0% errors, 0% empty values.\n",
    "\n",
    "---\n",
    "\n",
    "### **4️⃣ Best Practices**\n",
    "\n",
    "* **Profile first**: Always use Column Quality, Distribution, and Profile before cleaning.\n",
    "* **Document corrections** in step names in Applied Steps pane.\n",
    "* **Filter early** to avoid processing unnecessary rows.\n",
    "* Combine **data type checks** with business rules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592563c6",
   "metadata": {},
   "source": [
    "## 🔶 **15. Dataset Endorsement & Governance in Power BI**\n",
    "\n",
    "---\n",
    "\n",
    "### **1️⃣ What is Dataset Endorsement?**\n",
    "\n",
    "Dataset endorsement is a **trust mechanism** in Power BI that helps users identify **high-quality, reliable datasets** to use in reports and dashboards.\n",
    "It reduces the risk of using **outdated** or **unverified** data.\n",
    "\n",
    "---\n",
    "\n",
    "### **2️⃣ Two Types of Endorsement**\n",
    "\n",
    "#### **A. Promotion**\n",
    "\n",
    "* **Purpose:** Highlight datasets so more users in the organization can find and use them.\n",
    "* **Who can promote:** Dataset owners and members with edit permissions.\n",
    "* **Scenario Example:**\n",
    "  You created a clean, well-structured sales dataset and want your team to use it instead of creating duplicates.\n",
    "\n",
    "---\n",
    "\n",
    "#### **B. Certification**\n",
    "\n",
    "* **Purpose:** Signifies that a dataset has been **verified, tested, and approved** by a **data governance or BI team**.\n",
    "* **Who can certify:** Usually only Power BI admins or authorized data stewards.\n",
    "* **Scenario Example:**\n",
    "  Finance department certifies a revenue dataset for company-wide reporting.\n",
    "\n",
    "---\n",
    "\n",
    "### **3️⃣ Governance in Power BI**\n",
    "\n",
    "Governance ensures that **data is managed, secure, and compliant** while remaining accessible to authorized users.\n",
    "\n",
    "**Key Governance Components:**\n",
    "\n",
    "* **Dataset ownership** → Clear responsibility for maintenance.\n",
    "* **Version control** → Keep datasets updated and avoid duplicates.\n",
    "* **Security levels**:\n",
    "\n",
    "  * **Private** → Only you can access the data.\n",
    "  * **Organizational** → Shared within the company.\n",
    "  * **Public** → Accessible by anyone on the internet.\n",
    "\n",
    "---\n",
    "\n",
    "### **4️⃣ Benefits of Endorsement & Governance**\n",
    "\n",
    "* **Trust** → Users know the data source is accurate and approved.\n",
    "* **Efficiency** → Reduces duplication of datasets.\n",
    "* **Consistency** → All reports are built from the same source of truth.\n",
    "* **Compliance** → Meets organizational and legal data handling rules.\n",
    "\n",
    "---\n",
    "\n",
    "### **5️⃣ Best Practices**\n",
    "\n",
    "* Always use **certified datasets** for important business reporting.\n",
    "* If you create a dataset for team use, **promote it**.\n",
    "* Keep metadata (column descriptions, last refresh date) up to date.\n",
    "* Apply appropriate **privacy levels**:\n",
    "\n",
    "  * **Private** → Personal or sensitive data.\n",
    "  * **Organizational** → Internal sharing.\n",
    "  * **Public** → Public datasets like government statistics.\n",
    "\n",
    "---\n",
    "\n",
    "✅ **In Our Course Context:**\n",
    "Although we mostly worked in Power BI Desktop with local Excel files (`Order2022.xlsx`, `Order2023.xlsx`, `OrderDetails.xlsx`), if this project were published to the Power BI Service:\n",
    "\n",
    "* The final merged dataset could be **promoted** for the sales analysis team.\n",
    "* Once verified by the BI governance team, it could be **certified** for organization-wide usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e448e82",
   "metadata": {},
   "source": [
    "## 🔶 **16. Best Practices for ETL in Power BI**\n",
    "\n",
    "---\n",
    "\n",
    "### **1️⃣ General ETL Principles in Power BI**\n",
    "\n",
    "ETL (**Extract, Transform, Load**) is not just about moving data; it’s about **optimizing data for analysis** while ensuring **performance, accuracy, and maintainability**.\n",
    "\n",
    "Following best practices ensures:\n",
    "\n",
    "* Faster refresh times\n",
    "* Lower memory usage\n",
    "* Better user experience in reports\n",
    "* Easier collaboration and governance\n",
    "\n",
    "---\n",
    "\n",
    "### **2️⃣ Extract Phase – Best Practices**\n",
    "\n",
    "* **Filter early at the source** → Reduce the amount of data imported.\n",
    "  Example: Instead of loading all years of sales data, load only relevant years.\n",
    "* **Choose the right storage mode**:\n",
    "\n",
    "  * **Import** for speed (cached in memory)\n",
    "  * **DirectQuery** for real-time needs\n",
    "  * **Dual** for hybrid use\n",
    "* **Use Query Parameters** to make data extraction **dynamic**.\n",
    "  Example: Set a parameter for `Year` to pull different year data without editing queries.\n",
    "\n",
    "---\n",
    "\n",
    "### **3️⃣ Transform Phase – Best Practices**\n",
    "\n",
    "* **Remove unnecessary columns** early → This reduces memory consumption.\n",
    "* **Handle errors and nulls** before analysis:\n",
    "\n",
    "  * Replace missing values where appropriate\n",
    "  * Remove or correct invalid entries\n",
    "* **Use numeric join keys** (instead of text) for better performance.\n",
    "* **Defer expensive operations** like:\n",
    "\n",
    "  * Merging large tables\n",
    "  * Applying multiple transformations on big datasets\n",
    "    ➡ Do them **later in the process** after filtering down the dataset.\n",
    "* **Profile your data** using:\n",
    "\n",
    "  * **Column Quality** (valid/error/empty)\n",
    "  * **Column Distribution** (distinct/unique)\n",
    "  * **Column Profile** (min/max/mean)\n",
    "* **Use Reference Queries** for reusability instead of duplicating queries.\n",
    "\n",
    "---\n",
    "\n",
    "### **4️⃣ Load Phase – Best Practices**\n",
    "\n",
    "* **Disable load for intermediate/staging queries** → Keeps the data model clean.\n",
    "* Use **staging area** queries to prepare data for final models.\n",
    "* Apply **appropriate data types** before loading — reduces Power BI processing load.\n",
    "* Avoid loading huge unused lookup tables.\n",
    "\n",
    "---\n",
    "\n",
    "### **5️⃣ Governance & Collaboration Practices**\n",
    "\n",
    "* **Document your transformations** in query names and descriptions.\n",
    "* Use **dataset endorsement** (Promotion/Certification) in Power BI Service.\n",
    "* Apply **Privacy Levels** to ensure secure data sharing.\n",
    "\n",
    "---\n",
    "\n",
    "### **6️⃣ Performance Optimization Tips**\n",
    "\n",
    "* Push transformations to the **data source** (Query Folding) when possible.\n",
    "* Use **Aggregations** for large fact tables.\n",
    "* Avoid complex calculated columns in the model — do them in Power Query when possible.\n",
    "* Minimize **many-to-many relationships**.\n",
    "\n",
    "---\n",
    "\n",
    "### **7️⃣ In the Course Project – Applied Best Practices**\n",
    "\n",
    "During the **\"Transforming Multiple Data Sources\"** activity, these practices were followed:\n",
    "\n",
    "* **Filtered anomalies early**: Removed 3 invalid `UnitPrice` values before appending tables.\n",
    "* **Removed unnecessary columns**: In `OrderDetails`, kept only `SalesOrderID`, `ProductID`, `OrderQty`, `UnitPrice`.\n",
    "* **Used Append Queries**: Combined `Order2022` and `Order2023` into `Orders`.\n",
    "* **Used Merge Queries**: Joined `Orders` with `OrderDetails` using `SalesOrderID` (Inner Join).\n",
    "* **Expanded only required column**: Chose `OrderDate` only, instead of loading entire `Orders` table again.\n",
    "* **Renamed columns** for clarity (`Orders.OrderDate` → `OrderDate`).\n",
    "* **Profiled data** before and after transformation to ensure data accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85670e18",
   "metadata": {},
   "source": [
    "## 🔶 **17. Activities & Final Project Summary – Transforming Multiple Data Sources**\n",
    "\n",
    "The final project was designed to put **all ETL skills into practice** using three Excel files:\n",
    "\n",
    "* `Order2022.xlsx` – Sales orders for 2022\n",
    "* `Order2023.xlsx` – Sales orders for 2023\n",
    "* `OrderDetails.xlsx` – Details of each order (products, quantities, prices)\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 1 – Setup**\n",
    "\n",
    "* Open **Power BI Desktop**.\n",
    "* **Get Data** → Import the three Excel files.\n",
    "* **Transform Data** → Open **Power Query Editor**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 2 – Clean OrderDetails Table**\n",
    "\n",
    "1. Select `OrderDetails` query.\n",
    "2. **Keep only required columns**:\n",
    "\n",
    "   * `SalesOrderID`\n",
    "   * `ProductID`\n",
    "   * `OrderQty`\n",
    "   * `UnitPrice`\n",
    "3. Remove other columns to reduce dataset size and memory usage.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 3 – Profile the Data**\n",
    "\n",
    "* Enable:\n",
    "\n",
    "  * **Column Quality** → Shows % Valid, Error, Empty values.\n",
    "  * **Column Distribution** → Shows Distinct & Unique counts.\n",
    "  * **Column Profile** → Shows Min, Max, Mean, Std Dev.\n",
    "* Purpose:\n",
    "\n",
    "  * Detect data anomalies.\n",
    "  * Identify empty or invalid entries.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 4 – Detect & Remove Anomalies**\n",
    "\n",
    "1. Look at `UnitPrice` column stats.\n",
    "2. Found **3 rows with unusual values** (outliers — likely data entry mistakes).\n",
    "3. Filter them out by:\n",
    "\n",
    "   * Clicking filter on `UnitPrice`\n",
    "   * Unchecking the anomalous values.\n",
    "4. Result:\n",
    "\n",
    "   * Data is now accurate for analysis.\n",
    "   * Remaining: `27 distinct` and `6 unique` values for `UnitPrice`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 5 – Append Order Data**\n",
    "\n",
    "1. Select **Append Queries as New**.\n",
    "2. Append `Order2022` + `Order2023`.\n",
    "3. Rename new query to **Orders**.\n",
    "4. Check:\n",
    "\n",
    "   * Column names match.\n",
    "   * All rows from both years are combined.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 6 – Merge Orders with OrderDetails**\n",
    "\n",
    "1. Select `OrderDetails` query.\n",
    "2. Choose **Merge Queries**.\n",
    "3. Set:\n",
    "\n",
    "   * **Primary table**: OrderDetails\n",
    "   * **Secondary table**: Orders\n",
    "   * Join column: `SalesOrderID` in both tables.\n",
    "   * Join type: **Inner Join** (only matching orders).\n",
    "4. Expand merged table:\n",
    "\n",
    "   * Select only `OrderDate` from Orders.\n",
    "5. Rename column `Orders.OrderDate` → `OrderDate`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 7 – Final Checks**\n",
    "\n",
    "* Review row counts.\n",
    "* Ensure no unnecessary columns remain.\n",
    "* Verify `OrderDate` correctly matches `SalesOrderID`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 8 – Load Data**\n",
    "\n",
    "* Disable load for intermediate queries (like `Order2022` and `Order2023` if not used directly in reporting).\n",
    "* Close & Apply changes.\n",
    "* Dataset is ready for building visuals.\n",
    "\n",
    "---\n",
    "\n",
    "### **Final ETL Flow Recap**\n",
    "\n",
    "* **Extract**: Imported multiple Excel files (local datasets).\n",
    "* **Transform**:\n",
    "\n",
    "  * Removed unnecessary columns.\n",
    "  * Profiled data for quality checks.\n",
    "  * Removed anomalies from `UnitPrice`.\n",
    "  * Appended yearly sales data.\n",
    "  * Merged sales with order details.\n",
    "* **Load**: Loaded cleaned, accurate dataset into Power BI for analysis.\n",
    "\n",
    "---\n",
    "\n",
    "✅ **Outcome**: You now have **a clean, merged, and ready-to-analyze dataset** that can be used for creating sales performance dashboards, product analysis reports, and trends over time."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
